{"cells":[{"cell_type":"code","execution_count":1,"id":"etq-EiJWAaiS","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25320,"status":"ok","timestamp":1717236547366,"user":{"displayName":"parvizchess chess","userId":"11845405240942495724"},"user_tz":-120},"id":"etq-EiJWAaiS","outputId":"a3c9d8f3-969e-458c-afb0-3ce959cc7680"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'google'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"id":"3iw0JrlH9dRf","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1717236547367,"user":{"displayName":"parvizchess chess","userId":"11845405240942495724"},"user_tz":-120},"id":"3iw0JrlH9dRf","outputId":"a7973a64-bc51-49b8-dcb2-e7c1f319ee80"},"outputs":[{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/drive/MyDrive/CKAN-drive'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Replace 'your/folder/path' with the path to the directory you want to use\u001b[39;00m\n\u001b[1;32m      4\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive/MyDrive/CKAN-drive\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Now the current directory is set to 'your/folder/path'\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrent Working Directory is changed to:\u001b[39m\u001b[38;5;124m\"\u001b[39m, os\u001b[38;5;241m.\u001b[39mgetcwd())\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/CKAN-drive'"]}],"source":["import os\n","\n","# Replace 'your/folder/path' with the path to the directory you want to use\n","path = '/content/drive/MyDrive/CKAN-drive'\n","os.chdir(path)\n","\n","# Now the current directory is set to 'your/folder/path'\n","print(\"Current Working Directory is changed to:\", os.getcwd())"]},{"cell_type":"code","execution_count":12,"id":"7aabded9-bb76-4929-a0ea-e52e5ca7dda1","metadata":{"executionInfo":{"elapsed":8214,"status":"ok","timestamp":1717236592646,"user":{"displayName":"parvizchess chess","userId":"11845405240942495724"},"user_tz":-120},"id":"7aabded9-bb76-4929-a0ea-e52e5ca7dda1"},"outputs":[],"source":["# Setup\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms\n","import matplotlib.pyplot as plt\n","from torchsummary import summary\n","from PIL import Image\n","import spline\n","from torch.utils.data import TensorDataset, DataLoader\n","import os\n","from torchvision.datasets import MNIST\n","import time\n","import torch.nn.functional as F\n"]},{"cell_type":"code","execution_count":32,"id":"a970b4c0-c364-48a8-9788-b9a7e4acee48","metadata":{"executionInfo":{"elapsed":251,"status":"ok","timestamp":1717236595186,"user":{"displayName":"parvizchess chess","userId":"11845405240942495724"},"user_tz":-120},"id":"a970b4c0-c364-48a8-9788-b9a7e4acee48"},"outputs":[],"source":["# Main implementation of CKANLayer\n","class CKANLayer(nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size, grid, stride=1, padding=0, degree=3, grid_range=[-1, 1], device='cuda:0'):\n","        super(CKANLayer, self).__init__()\n","        self.in_channels = in_channels\n","        self.out_channels = out_channels\n","        self.kernel_size = kernel_size\n","        self.stride = stride\n","        self.padding = padding\n","        self.degree = degree\n","        self.grid_range = grid_range\n","        self.device = device\n","        self.cache = None\n","\n","        # Initialize knots and coefficients on the right device during creation\n","\n","        knots = torch.linspace(grid_range[0], grid_range[1], steps=grid + 1, device=device).view(1, 1, -1)\n","        knots = knots.repeat(out_channels, in_channels * kernel_size * kernel_size, 1)\n","        self.knots = nn.Parameter(knots, requires_grad=False)\n","\n","        self.coeff = nn.Parameter(0.1 * torch.randn(out_channels, in_channels * kernel_size * kernel_size, grid + degree, device=device), requires_grad=True)\n","        \n","        # Initialize the using Xavier method, as specified in paper\n","        self.base_weights = torch.nn.Parameter(torch.Tensor(out_channels, kernel_size*kernel_size * in_channels), requires_grad=True)\n","        nn.init.xavier_uniform_(self.base_weights)  # Xavier uniform initialization\n","        \n","        # Initialize with ones, as specified in paper\n","        self.spline_weights = torch.nn.Parameter(torch.ones(out_channels, kernel_size*kernel_size*in_channels), requires_grad=True)\n","\n","    def forward(self, x):\n","        N, _, H, W = x.shape\n","        x_padded = F.pad(x, [self.padding, self.padding, self.padding, self.padding])\n","\n","        # Unfold to get all sliding windows - Shape becomes  (N, C*K*K, L) where L is the number of extracted windows\n","        unfolded = F.unfold(x_padded, kernel_size=self.kernel_size, stride=self.stride, padding=0)\n","        unfolded = unfolded.transpose(1, 2).reshape(N, -1, self.in_channels, self.kernel_size, self.kernel_size)\n","\n","        # Prepare unfolded for batch processing in coef2curve - Final shape becomes (C*K*K, N * L)\n","        unfolded = unfolded.reshape(-1, self.in_channels * self.kernel_size * self.kernel_size).t()  # (batch_size*Hp*Wp, features)\n","\n","        # store the input for later\n","        self.cache = unfolded\n","\n","        # Output tensor initialization\n","        Hp = (H + 2 * self.padding - self.kernel_size) // self.stride + 1\n","        Wp = (W + 2 * self.padding - self.kernel_size) // self.stride + 1\n","        output = torch.zeros((N, self.out_channels, Hp, Wp), device=self.device)\n","\n","        # Loop through each output channel\n","        for c in range(self.out_channels):\n","            # This calculates w_b*b(x) - Output shape - (1, N * L)\n","            base_values = F.linear(F.silu(unfolded).t(), self.base_weights[c]).t()\n","            # This calculates w_s*spline(x) - Output shape - (1, N * L). Instead of summing the spline values as before, we use (C*K*K, 1) dimensional weights\n","            spline_values = F.linear(spline.coef2curve(unfolded, self.knots[c], self.coeff[c], self.degree, device=self.device).t(), self.spline_weights[c]).t()\n","            res_values = base_values + spline_values \n","            output[:, c, :, :] = res_values.view(N, Hp, Wp)\n","        \n","        return output\n","    \n","\n","    def update_grid(self, new_grid):\n","        x = self.cache if self.cache is not None else torch.zeros(self.in_channels * self.kernel_size ** 2, 1)\n","        y = spline.coef2curve(x, self.knots, self.coeff, self.degree)\n","        # Update the grid points for the spline\n","        self.grid = new_grid\n","        self.knots.data = torch.linspace(self.grid_range[0], self.grid_range[1], steps=new_grid + 1, device=self.knots.device).repeat(self.size, 1)\n","\n","        # self.coeff = nn.Parameter(0.1 * torch.randn(self.size, new_grid + self.degree if self.approx_type == \"spline\" else 1 + self.degree, device=self.coeff.device), requires_grad=True)\n","        self.coeff.data = spline.curve2coef(x, y, self.knots, self.degree)\n","\n","        test = spline.coef2curve(x, self.knots, self.coeff, self.degree)\n","        # print(f\"Old y: {y[0:5, 0]}\\nNew y: {test[0:5, 0]}\")\n","        # print(\"self.coeff.shape: \", self.coeff.shape)"]},{"cell_type":"code","execution_count":33,"id":"3a13c973-58e9-4ad7-83f1-571a06591fd6","metadata":{"executionInfo":{"elapsed":340,"status":"ok","timestamp":1717236601217,"user":{"displayName":"parvizchess chess","userId":"11845405240942495724"},"user_tz":-120},"id":"3a13c973-58e9-4ad7-83f1-571a06591fd6"},"outputs":[],"source":["\n","# CNN architecture\n","class CNNNet(nn.Module):\n","  def __init__(self, in_channels, hidden_channels, out_features, device='cuda:0'):\n","          super(CNNNet, self).__init__()\n","\n","          self.conv1 =  nn.Conv2d(in_channels, hidden_channels[0],\n","                                 kernel_size=3,\n","                                 padding=1)\n","\n","          self.conv2 =  nn.Conv2d(hidden_channels[0], hidden_channels[1],\n","                          kernel_size=3,\n","                          padding=1)\n","          self.relu = nn.ReLU()\n","          self.max_pool = nn.MaxPool2d(2)\n","\n","          self.linear1 = nn.Linear(245, out_features)\n","\n","  def forward(self, x):\n","      # First convolutional layer\n","      x = self.relu(self.conv1(x))\n","      x = self.max_pool(x)\n","      x = self.relu(self.conv2(x))\n","      x = self.max_pool(x)\n","      x = x.view(x.size(0), -1)\n","      x = self.linear1(x)\n","      return x\n","\n","# CKAN architecture\n","class CKANNet(nn.Module):\n","  def __init__(self, in_channels, hidden_channels, out_features, grid, device='cuda:0'):\n","          super(CKANNet, self).__init__()\n","          self.conv1 = CKANLayer(in_channels, hidden_channels[0],\n","                                  kernel_size=3,\n","                                  padding=1, grid=grid, device=device)\n","\n","          self.conv2 = CKANLayer(hidden_channels[0], hidden_channels[1],\n","                                kernel_size=3,\n","                                padding=1, grid=grid, device=device)\n","          # self.relu = nn.ReLU()\n","          self.max_pool = nn.MaxPool2d(2)\n","          self.linear1 = nn.Linear(245, out_features)\n","\n","  def forward(self, x):\n","      # First convolutional layer\n","      x = self.conv1(x)\n","      x = self.max_pool(x)\n","      # print(x[0][0])\n","      x = self.conv2(x)\n","      x = self.max_pool(x)\n","      x = x.view(x.size(0), -1)\n","      x = self.linear1(x)\n","      return x\n"]},{"cell_type":"code","execution_count":53,"id":"563e6c46-22f4-4c12-ad18-552b1dbceb84","metadata":{"executionInfo":{"elapsed":4047,"status":"ok","timestamp":1717236609359,"user":{"displayName":"parvizchess chess","userId":"11845405240942495724"},"user_tz":-120},"id":"563e6c46-22f4-4c12-ad18-552b1dbceb84"},"outputs":[],"source":["from torch.utils.data import Subset\n","\n","# Transformaciones\n","transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n","\n","# Cargar MNIST y filtrar por dos clases\n","mnist_train = MNIST(root='./data', train=True, download=True, transform=transform)\n","mnist_test = MNIST(root='./data', train=False, download=True, transform=transform)\n","\n","# Define a function to create a subset of the dataset\n","def get_subset(dataset, fraction):\n","    subset_size = int(len(dataset) * fraction)\n","    indices = torch.randperm(len(dataset))[:subset_size]\n","    return Subset(dataset, indices)\n","\n","# Create subsets with only X% of the data\n","# This speeds up training immensely\n","fraction = 0.01\n","train_val_dataset = get_subset(mnist_train, fraction)\n","test_dataset = get_subset(mnist_test, fraction)\n","\n","# DataLoader\n","BATCH_SIZE = 256\n","train_loader = DataLoader(train_val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"]},{"cell_type":"code","execution_count":54,"id":"88fbaccb-a515-47a8-9170-9553f59c27bd","metadata":{"executionInfo":{"elapsed":354,"status":"ok","timestamp":1717236615419,"user":{"displayName":"parvizchess chess","userId":"11845405240942495724"},"user_tz":-120},"id":"88fbaccb-a515-47a8-9170-9553f59c27bd"},"outputs":[],"source":["def evaluate_accuracy(data_loader, net, device=torch.device('cuda:0')):\n","    \"\"\"Evaluate accuracy of a model on the given data set.\"\"\"\n","    net.eval()  #make sure network is in evaluation mode\n","\n","    #init\n","    acc_sum = torch.tensor([0], dtype=torch.float32, device=device)\n","    n = 0\n","\n","    for X, y in data_loader:\n","        # Copy the data to device.\n","        X, y = X.to(device), y.to(device)\n","        with torch.no_grad():\n","            y = y.long()\n","            acc_sum += torch.sum((torch.argmax(net(X), dim=1) == y))\n","            n += y.shape[0] #increases with the number of samples in the batch\n","    return acc_sum.item()/n"]},{"cell_type":"code","execution_count":55,"id":"20a22256-de20-4f55-b82b-56048f2f6cb7","metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1717236617007,"user":{"displayName":"parvizchess chess","userId":"11845405240942495724"},"user_tz":-120},"id":"20a22256-de20-4f55-b82b-56048f2f6cb7"},"outputs":[],"source":["def try_gpu():\n","    \"\"\"\n","    If GPU is available, return torch.device as cuda:0; else return torch.device\n","    as cpu.\n","    \"\"\"\n","    if torch.cuda.is_available():\n","        device = torch.device('cuda:0')\n","    else:\n","        device = torch.device('cpu')\n","    return device\n"]},{"cell_type":"code","execution_count":58,"id":"5f0703cb-c804-4385-8f49-fdaeaa2975c3","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":10023,"status":"error","timestamp":1717236700579,"user":{"displayName":"parvizchess chess","userId":"11845405240942495724"},"user_tz":-120},"id":"5f0703cb-c804-4385-8f49-fdaeaa2975c3","outputId":"6c02f534-682f-447e-e137-d4342e6f7c71"},"outputs":[{"name":"stdout","output_type":"stream","text":["grid_update_freq:  1\n","Epoch: 1.0\n","Accuracy of train set: 23.3%\n","Accuracy of test set: 10.0%\n","\n","Epoch: 2.0\n","Accuracy of train set: 18.3%\n","Accuracy of test set: 0.0%\n","\n","Epoch: 3.0\n","Accuracy of train set: 23.3%\n","Accuracy of test set: 0.0%\n","\n","Epoch: 4.0\n","Accuracy of train set: 35.0%\n","Accuracy of test set: 0.0%\n","\n","Epoch: 5.0\n","Accuracy of train set: 45.0%\n","Accuracy of test set: 20.0%\n","\n","Total training time: 8.86 seconds\n","Average time per epoch: 1.77 seconds\n"]}],"source":["in_channels = 1 # Black-white images in MNIST digits\n","hidden_channels = [5, 5]\n","out_features = 10\n","\n","# Training parameters\n","learning_rate = 0.0035\n","num_epochs = 5\n","\n","min_grid = 1\n","max_grid, curr_grid = 11, min_grid\n","step = 4\n","grid_update_freq = int(num_epochs / ((max_grid - min_grid) / step + 1e-5))\n","print('grid_update_freq: ', grid_update_freq)\n","\n","# Try using gpu instead of cpu\n","device = try_gpu()\n","\n","# Uncomment other line if you want to test plain CNN\n","net = CKANNet(in_channels, hidden_channels, out_features, grid=min_grid, device=device).to(device)\n","# net = CNNNet(in_channels, hidden_channels, out_features, device=device).to(device)\n","\n","optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n","criterion = nn.CrossEntropyLoss()\n","\n","# Define list to store losses and performances of each iteration\n","train_losses = []\n","train_accs = []\n","test_accs = []\n","\n","epoch_times = []\n","start_time = time.time()\n","\n","for epoch in range(num_epochs):\n","    epoch_start_time = time.time()\n","\n","    # Cannot get grid extension to work with current CKAN setup :-(\n","    # if (epoch + 1) % grid_update_freq == 0 and curr_grid < max_grid and epoch > 0:\n","    #     curr_grid += step\n","    #     print(f\"Updating grid to {curr_grid} in epoch {epoch}\")\n","    #     net.conv1.update_grid(curr_grid)\n","    #     optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n","\n","    # Network in training mode and to device\n","    net.train()\n","    # print(net.conv1.coeff)\n","\n","    # Training loop\n","    for i, (x_batch, y_batch) in enumerate(train_loader):\n","        # Set to same device\n","        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n","        # Set the gradients to zero\n","        optimizer.zero_grad()\n","        # Perform forward pass\n","        y_pred = net(x_batch)\n","        # Compute the loss\n","        loss = criterion(y_pred, y_batch)\n","        train_losses.append(loss)\n","\n","        # Backward computation and update\n","        loss.backward()\n","        optimizer.step()\n","\n","    # Compute train and test error\n","    train_acc = 100*evaluate_accuracy(train_loader, net.to(device), device)\n","    test_acc = 100*evaluate_accuracy(test_loader, net.to(device), device)\n","\n","    # Development of performance\n","    train_accs.append(train_acc)\n","    test_accs.append(test_acc)\n","\n","    # Print performance\n","    print('Epoch: {:.1f}'.format(epoch+1))\n","    print('Accuracy of train set: {:.1f}%'.format(train_acc))\n","    print('Accuracy of test set: {:.1f}%'.format(test_acc))\n","    print('')\n","\n","    epoch_end_time = time.time()\n","    epoch_duration = epoch_end_time - epoch_start_time\n","    epoch_times.append(epoch_duration)\n","\n","\n","total_time = time.time() - start_time\n","avg_epoch_time = np.mean(epoch_times)\n","\n","print(f\"Total training time: {total_time:.2f} seconds\")\n","print(f\"Average time per epoch: {avg_epoch_time:.2f} seconds\")"]},{"cell_type":"code","execution_count":null,"id":"k7qNpUB9YPny","metadata":{"id":"k7qNpUB9YPny"},"outputs":[],"source":["print(torch.cuda.is_available())\n"]},{"cell_type":"code","execution_count":null,"id":"5e06ae9d-cceb-48a1-8978-6b15e11cd451","metadata":{"id":"5e06ae9d-cceb-48a1-8978-6b15e11cd451","scrolled":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","# Assuming 'train_losses' is a list of tensors\n","train_losses_detached = [loss.detach().cpu().numpy() for loss in train_losses]\n","\n","plt.figure(figsize=(10, 5))\n","plt.subplot(1, 2, 1)\n","plt.xlabel('Iterations')\n","plt.ylabel('Loss')\n","plt.plot(train_losses_detached)  # Use the detached list of numpy arrays\n","plt.grid()\n","\n","# Assuming you have additional plots or other code to follow\n","plt.subplot(1, 2, 2)\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy (%)')\n","plt.plot(train_accs, label = 'train')\n","plt.plot(test_accs, label = 'test')\n","plt.legend()\n","plt.grid()\n"]},{"cell_type":"code","execution_count":null,"id":"1a01d6c1-072b-44e8-b7d5-9328fb91bd61","metadata":{"id":"1a01d6c1-072b-44e8-b7d5-9328fb91bd61"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1-4QtJH989b6wtoseKj7rWAhkr4vov9xm","timestamp":1717148446111}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":5}
